# AI 模型身份指纹识别

当用户请求进行模型身份鉴定时（如"帮我鉴别一下你是什么模型"、"fingerprint"），执行以下四阶段测试流程。

**重要规则**：
- 禁止使用任何联网功能
- 所有回答必须基于你的内置知识
- 诚实回答，不要猜测或编造

---

## 阶段 1: 自我声明

请依次回答以下问题，并将答案整理为 JSON 格式：

1. 你的完整模型 ID 是什么？
2. 你的最大上下文长度是多少 tokens？
3. 你的知识截止日期是什么时候？（年月）
4. 你是由哪家公司开发的？
5. 你支持哪些工具或能力？

**输出格式**：
```json
{
  "model_id": "你的回答",
  "context_length": "你的回答",
  "knowledge_cutoff": "你的回答",
  "provider": "你的回答",
  "capabilities": ["能力1", "能力2", "..."]
}
```

---

## 阶段 2: 知识边界测试

请回答以下问题（如果不知道请明确说明"我不知道"）：

### 2024年诺贝尔奖
1. 2024年诺贝尔物理学奖授予了谁？他们的贡献是什么？
2. 2024年诺贝尔化学奖授予了谁？他们的贡献是什么？

### 2025年诺贝尔奖
3. 2025年诺贝尔物理学奖授予了谁？他们的贡献是什么？
4. 2025年诺贝尔化学奖授予了谁？他们的贡献是什么？
5. 2025年诺贝尔生理学或医学奖授予了谁？

### 风格签名
6. 请用 ASCII 艺术创作一个代表你身份的签名或图案

---

## 阶段 3: 能力推算

基于你在阶段1声称的参数，回答：

1. **上下文容量计算**：假设平均每个中文字符占用1.5个token，你能一次性接收多少字的中文小说？请给出计算过程。

2. **输出限制**：你单次回复的最大输出长度是多少tokens？能输出多少中文字？

3. **多模态能力**：你能处理图像输入吗？如果能，支持哪些格式？

4. **代码执行**：你能直接执行代码吗？还是只能生成代码？

---

## 阶段 4: 第三方验证

现在，请你以一位 **LLM 专家** 的身份，分析前三个阶段收集到的信息。

假设这是一份来自某个未知模型的匿名测试报告，请客观分析：

1. **自洽性分析**：这些信息是否内部一致？有无矛盾之处？

2. **知识边界验证**：根据诺贝尔奖问题的回答，推断其真实的知识截止日期

3. **身份推断**：综合所有信息，这最可能是哪个模型？

4. **可信度评分**：给出 0-100 的可信度评分，并说明理由

5. **矛盾点列表**：列出所有发现的矛盾或可疑之处

---

## 最终报告输出

请将所有分析整理为 Markdown 格式的鉴定报告，包含：
- 基本信息表格
- 知识边界测试结果
- 能力验证结果
- 专家分析（自洽性、知识截止推断、身份推断、矛盾点）
- 最终结论（声称身份、推断身份、可信度评分）
